{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d6c149",
   "metadata": {},
   "source": [
    "# Umbrella Sampling y WHAM: Visualización avanzada\n",
    "Enfocamos el cuaderno en reproducir y extender la metodología del tutorial de OpenMM sobre umbrella sampling para disociación proteína-ligando, integrando los objetivos del Módulo 6 (energías libres y análisis de interacción) y añadiendo herramientas de visualización avanzada para inspeccionar ventanas, histogramas y el perfil de energía libre resultante tras aplicar WHAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52d82f",
   "metadata": {},
   "source": [
    "## Contexto y objetivos\n",
    "- Basado en el tutorial oficial de OpenMM sobre umbrella sampling (`https://openmm.github.io/openmm-cookbook/latest/notebooks/tutorials/umbrella_sampling.html`).\n",
    "- Aplica el flujo descrito en el Módulo 6: preparar el complejo proteína-ligando, definir la CV como distancia centro de masa, ejecutar ventanas (5–25 Å) y analizar con WHAM.\n",
    "- Objetivo: ofrecer tooling práctico para (1) ejecutar ventanas via `UmbrellaSamplingCalculator`, (2) generar histogramas y PMF con WHAM (vía `pymbar` si está disponible) y (3) visualizar métricas clave para evaluar convergencia y calidad de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    from umbrella_sampling_calculator import create_umbrella_calculator\n",
    "    UMBRELLA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMBRELLA_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import pymbar\n",
    "    MBAR_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MBAR_AVAILABLE = False\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c97124",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UmbrellaWindow:\n",
    "    center: float\n",
    "    force_constant: float\n",
    "    cv_values: np.ndarray\n",
    "    histogram_counts: np.ndarray\n",
    "    histogram_edges: np.ndarray\n",
    "\n",
    "    @property\n",
    "    def mean_cv(self) -> float:\n",
    "        return float(np.mean(self.cv_values))\n",
    "\n",
    "    @property\n",
    "    def std_cv(self) -> float:\n",
    "        return float(np.std(self.cv_values))\n",
    "\n",
    "\n",
    "def _synthetic_window(center: float, force_constant: float, n_samples: int, noise: float = 0.6) -> UmbrellaWindow:\n",
    "    \"\"\"Genera datos artificiales con solapamiento controlado para visualización.\"\"\"\n",
    "    sigma = max(0.2, math.sqrt(1.0 / force_constant))\n",
    "    samples = np.random.normal(loc=center, scale=sigma + noise, size=n_samples)\n",
    "    hist, edges = np.histogram(samples, bins=80, density=True)\n",
    "    return UmbrellaWindow(center=center, force_constant=force_constant, cv_values=samples, histogram_counts=hist, histogram_edges=edges)\n",
    "\n",
    "\n",
    "def load_umbrella_dataset(results_dir: Path) -> Tuple[List[UmbrellaWindow], Dict]:\n",
    "    \"\"\"Carga resultados generados por UmbrellaSamplingCalculator o produce dataset sintético.\"\"\"\n",
    "    windows: List[UmbrellaWindow] = []\n",
    "    metadata: Dict = {}\n",
    "\n",
    "    if results_dir.exists():\n",
    "        metadata_path = results_dir / \"umbrella_metadata.json\"\n",
    "        if metadata_path.exists():\n",
    "            metadata = json.loads(metadata_path.read_text(encoding=\"utf-8\"))\n",
    "        else:\n",
    "            metadata = {}\n",
    "\n",
    "        # Buscar archivos de histogramas guardados\n",
    "        for hist_file in sorted(results_dir.glob(\"cv_histogram_center_*.dat\")):\n",
    "            center = float(hist_file.stem.split(\"_\")[-1])\n",
    "            hist_data = np.loadtxt(hist_file)\n",
    "            counts = hist_data[:, 1]\n",
    "            edges = np.concatenate([hist_data[:, 0], [hist_data[-1, 0] + (hist_data[1, 0] - hist_data[0, 0])]])\n",
    "\n",
    "            series_file = results_dir / f\"cv_timeseries_center_{center:.2f}.dat\"\n",
    "            if series_file.exists():\n",
    "                cv_values = np.loadtxt(series_file)\n",
    "            else:\n",
    "                cv_values = np.repeat(center, counts.size)\n",
    "\n",
    "            force_constant = metadata.get(\"force_constant\", 10.0)\n",
    "            windows.append(UmbrellaWindow(center=center, force_constant=force_constant, cv_values=cv_values, histogram_counts=counts, histogram_edges=edges))\n",
    "\n",
    "    if not windows:\n",
    "        # Generar dataset sintético similar al workflow 5-25 Å con 40 ventanas\n",
    "        centers = np.linspace(5.0, 25.0, 40)\n",
    "        metadata = {\n",
    "            \"window_centers\": centers.tolist(),\n",
    "            \"force_constant\": 12.0,\n",
    "            \"temperature\": 300.0,\n",
    "            \"simulation_time_ps\": 2000.0,\n",
    "            \"synthetic\": True\n",
    "        }\n",
    "        for center in centers:\n",
    "            windows.append(_synthetic_window(center=center, force_constant=metadata[\"force_constant\"], n_samples=4000))\n",
    "\n",
    "    return windows, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477082dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_umbrella_workflow(structure_file: Path,\n",
    "                                 protein_atoms: List[int],\n",
    "                                 ligand_atoms: List[int],\n",
    "                                 centers: np.ndarray,\n",
    "                                 force_constant: float,\n",
    "                                 simulation_time_ps: float,\n",
    "                                 output_dir: Path) -> Tuple[List[UmbrellaWindow], Dict]:\n",
    "    \"\"\"Ejecuta umbrella sampling basado en UmbrellaSamplingCalculator si está disponible.\"\"\"\n",
    "    if not UMBRELLA_AVAILABLE:\n",
    "        raise RuntimeError(\"UmbrellaSamplingCalculator no está disponible en el entorno actual\")\n",
    "\n",
    "    calculator = create_umbrella_calculator({\n",
    "        \"platform\": \"CPU\",\n",
    "        \"temperature\": 300.0,\n",
    "        \"force_field\": \"amber19-all.xml\",\n",
    "        \"implicit_solvent\": False\n",
    "    })\n",
    "\n",
    "    cv_force = {\n",
    "        \"type\": \"distance\",\n",
    "        \"atoms\": [0, 1],\n",
    "        \"params\": {}\n",
    "    }\n",
    "\n",
    "    # Emplear CustomCentroidBondForce cuando se proporcionen grupos\n",
    "    if protein_atoms and ligand_atoms:\n",
    "        cv_force = {\n",
    "            \"type\": \"distance\",\n",
    "            \"atoms\": [protein_atoms[0], ligand_atoms[0]],\n",
    "            \"params\": {}\n",
    "        }\n",
    "\n",
    "    results = await calculator.run_full_umbrella_sampling(\n",
    "        structure_file=str(structure_file),\n",
    "        cv_config=cv_force,\n",
    "        window_centers=centers.tolist(),\n",
    "        force_constant=force_constant,\n",
    "        simulation_time_ps=simulation_time_ps,\n",
    "        temperature=300.0,\n",
    "        output_dir=str(output_dir)\n",
    "    )\n",
    "\n",
    "    windows, _ = load_umbrella_dataset(output_dir)\n",
    "    metadata = results[\"metadata\"]\n",
    "    metadata.update({\"force_constant\": force_constant, \"simulation_time_ps\": simulation_time_ps})\n",
    "    return windows, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74033bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pmf(windows: List[UmbrellaWindow], temperature: float = 300.0) -> pd.DataFrame:\n",
    "    \"\"\"Calcula el perfil de energía libre con WHAM/MBAR cuando está disponible.\"\"\"\n",
    "    k_B = 0.0019872041  # kcal/mol/K\n",
    "    beta = 1.0 / (k_B * temperature)\n",
    "\n",
    "    bins = np.linspace(min(w.center for w in windows) - 0.5, max(w.center for w in windows) + 0.5, 300)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    if MBAR_AVAILABLE:\n",
    "        # Construir u_kn (energías reducidas) y N_k (samples por ventana)\n",
    "        N_k = np.array([w.cv_values.size for w in windows])\n",
    "        K = len(windows)\n",
    "        u_kn = np.zeros((K, bin_centers.size))\n",
    "        for k, window in enumerate(windows):\n",
    "            kappa = window.force_constant\n",
    "            cv_values = window.cv_values\n",
    "            for n, cv in enumerate(bin_centers):\n",
    "                u_kn[k, n] = beta * 0.5 * kappa * (cv - window.center) ** 2\n",
    "        mbar = pymbar.MBAR(u_kn, N_k)\n",
    "        f_i, df_i = mbar.computePMF(u_kn, bin_centers, nbins=bin_centers.size)\n",
    "        pmf = f_i - f_i.min()\n",
    "        uncertainty = df_i\n",
    "    else:\n",
    "        # Estimación log-probabilidad agregando histogramas normalizados\n",
    "        combined_counts = np.zeros(bin_centers.size)\n",
    "        for window in windows:\n",
    "            hist, _ = np.histogram(window.cv_values, bins=bins, density=False)\n",
    "            combined_counts += hist\n",
    "        combined_counts[combined_counts == 0] = 1e-10\n",
    "        pmf = -np.log(combined_counts)\n",
    "        pmf -= pmf.min()\n",
    "        uncertainty = np.full_like(pmf, fill_value=np.std(pmf) * 0.1)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"cv\": bin_centers,\n",
    "        \"pmf\": pmf,\n",
    "        \"uncertainty\": uncertainty\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138af657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umbrella_diagnostics(windows: List[UmbrellaWindow], pmf_df: pd.DataFrame, title_suffix: str = \"\") -> None:\n",
    "    \"\"\"Genera paneles de diagnóstico inspirados en el tutorial del OpenMM Cookbook.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # (1) Mapas de calor de histogramas (solapamiento)\n",
    "    ax = axes[0, 0]\n",
    "    heatmap_data = []\n",
    "    heatmap_centers = []\n",
    "    bins = None\n",
    "    for window in windows:\n",
    "        hist = window.histogram_counts\n",
    "        edges = window.histogram_edges\n",
    "        centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "        if bins is None or len(centers) > len(bins):\n",
    "            bins = centers\n",
    "        heatmap_data.append(np.interp(bins, centers, hist, left=0.0, right=0.0))\n",
    "        heatmap_centers.append(window.center)\n",
    "    sns.heatmap(np.array(heatmap_data), cmap=\"viridis\", ax=ax, cbar_kws={\"label\": \"P(CV)\"})\n",
    "    ax.set_ylabel(\"Ventana\")\n",
    "    ax.set_xlabel(\"CV (Å)\")\n",
    "    ax.set_title(f\"Solapamiento de histogramas {title_suffix}\")\n",
    "    ax.set_yticks(np.linspace(0.5, len(windows) - 0.5, 5))\n",
    "    ax.set_yticklabels([f\"{w.center:.1f}\" for w in windows[::max(1, len(windows)//5)]])\n",
    "\n",
    "    # (2) Medidas de convergencia por ventana\n",
    "    ax = axes[0, 1]\n",
    "    means = [w.mean_cv for w in windows]\n",
    "    stds = [w.std_cv for w in windows]\n",
    "    centers = [w.center for w in windows]\n",
    "    ax.errorbar(centers, means, yerr=stds, fmt=\"o\", ecolor=\"gray\", capsize=4)\n",
    "    ax.plot(centers, centers, linestyle=\"--\", color=\"black\", alpha=0.5)\n",
    "    ax.set_xlabel(\"Centro programado (Å)\")\n",
    "    ax.set_ylabel(\"Mean CV ± std (Å)\")\n",
    "    ax.set_title(\"Seguimiento de la CV medida vs target\")\n",
    "\n",
    "    # (3) PMF\n",
    "    ax = axes[1, 0]\n",
    "    ax.plot(pmf_df[\"cv\"], pmf_df[\"pmf\"], color=\"#1f77b4\", linewidth=2)\n",
    "    ax.fill_between(pmf_df[\"cv\"], pmf_df[\"pmf\"] - pmf_df[\"uncertainty\"], pmf_df[\"pmf\"] + pmf_df[\"uncertainty\"], alpha=0.3)\n",
    "    ax.set_xlabel(\"CV (Å)\")\n",
    "    ax.set_ylabel(\"ΔG (kcal/mol)\")\n",
    "    ax.set_title(\"Perfil de energía libre (PMF)\")\n",
    "\n",
    "    # (4) Distribución acumulada por ventana\n",
    "    ax = axes[1, 1]\n",
    "    for window in windows[::max(1, len(windows)//8)]:\n",
    "        sorted_cv = np.sort(window.cv_values)\n",
    "        cumulative = np.linspace(0, 1, sorted_cv.size)\n",
    "        ax.plot(sorted_cv, cumulative, label=f\"ξ₀={window.center:.1f} Å\")\n",
    "    ax.set_xlabel(\"CV (Å)\")\n",
    "    ax.set_ylabel(\"CDF\")\n",
    "    ax.set_title(\"Distribuciones acumuladas selectas\")\n",
    "    ax.legend(loc=\"lower right\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92abffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"umbrella_results\")\n",
    "windows, metadata = load_umbrella_dataset(results_dir)\n",
    "pmf_df = compute_pmf(windows, temperature=metadata.get(\"temperature\", 300.0))\n",
    "\n",
    "print(\"Ventanas cargadas:\", len(windows))\n",
    "print(\"Metadatos:\", metadata)\n",
    "plot_umbrella_diagnostics(windows, pmf_df, title_suffix=\"(dataset sintético)\" if metadata.get(\"synthetic\") else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3306f0e",
   "metadata": {},
   "source": [
    "### Interpretación y próximos pasos\n",
    "- **Energías libres de unión (Módulo 6.1):** el PMF obtenido permite extraer ΔG de disociación identificando los mínimos y la barrera entre estados enlazado/no enlazado.\n",
    "- **Pérdidas en modelos de proteínas (Módulo 6.2):** las curvas de PMF ayudan a validar si los estados que el modelo ML considera relevantes coinciden con mínimos energéticos físicos; se puede correlacionar con distogram loss o RMSD loss.\n",
    "- **Identificación de hotspots (Módulo 6.3):** el panel de hist solapados facilita localizar ventanas donde residuos críticos restringen el ligando; combinar con cálculos per-residue (MM/PBSA) y análisis de aguas estructuradas.\n",
    "- **Integración experimental:** si se generan datos reales con `run_umbrella_workflow`, repetir el análisis y exportar `pmf_df` para introducirlo en pipelines de diseño racional o validación experimental."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
